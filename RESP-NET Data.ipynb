{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Respiratory Virus Hospitalization Surveillance Network (RESP-NET) Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitoring COVID-19, respiratory syncytial virus (RSV), and influenza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source: https://www.cdc.gov/resp-net/dashboard/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on Python 3.12 | No Errors | No Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "# For data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# For making HTTP requests\n",
    "import requests\n",
    "\n",
    "# For adding delays in between HTTP requests\n",
    "import time\n",
    "\n",
    "# For creating in-memory text streams\n",
    "from io import StringIO as sio\n",
    "\n",
    "# For creating and displaying progress bars\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the API endpoint\n",
    "url = \"https://data.cdc.gov/resource/kvib-3txy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get total record count with error handling\n",
    "def get_total_count():\n",
    "    try:\n",
    "        response = requests.get(f\"{url}.json\", params={\"$select\": \"count(*)\"})\n",
    "        response.raise_for_status()  # Check if the request was successful\n",
    "        data = response.json()\n",
    "        return int(data[0]['count'])\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred: {http_err}\")  # Print the HTTP error\n",
    "    except requests.exceptions.RequestException as req_err:\n",
    "        print(f\"Error occurred during the request: {req_err}\")  # Print other request errors\n",
    "    except Exception as err:\n",
    "        print(f\"An error occurred: {err}\")  # Print any other errors\n",
    "    return None  # Return None if there was an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total record count: 43007\n"
     ]
    }
   ],
   "source": [
    "# Get total record count\n",
    "total_count = get_total_count()\n",
    "\n",
    "if total_count is not None:\n",
    "    print(f\"Total record count: {total_count}\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the total record count.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "params = {\n",
    "    \"$limit\": 1000,  # Number of records per request\n",
    "    \"$offset\": 0     # Starting point for records\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Records: 100%|██████████| 43007/43007 [01:00<00:00, 712.23record/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the data\n",
    "data_list = []\n",
    "\n",
    "# Loop to fetch all records with progress bar\n",
    "with tqdm(total=total_count, desc=\"Downloading Records\", unit=\"record\") as pbar:\n",
    "    while params['$offset'] < total_count:\n",
    "        # Make the request to the API\n",
    "        response = requests.get(f\"{url}.csv\", params=params)\n",
    "\n",
    "        # Check if the response is successful\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error: Received status code {response.status_code}\")\n",
    "            print(f\"Response: {response.text}\")\n",
    "            break\n",
    "\n",
    "        # Attempt to parse the response as CSV\n",
    "        try:\n",
    "            data = pd.read_csv(sio(response.text))\n",
    "        except Exception as e:\n",
    "            print(f\"Error: Unable to parse response as CSV: {e}\")\n",
    "            break\n",
    "\n",
    "        # Check if there are records in the response\n",
    "        if data.empty:\n",
    "            print(\"No data to fetch.\")\n",
    "            break\n",
    "\n",
    "        # Append the data to the list\n",
    "        data_list.append(data)\n",
    "\n",
    "        # Update the progress bar\n",
    "        pbar.update(len(data))\n",
    "\n",
    "        # Increment the offset for the next request\n",
    "        params['$offset'] += params['$limit']\n",
    "\n",
    "        # Delay between requests to handle rate limiting\n",
    "        time.sleep(1)  # Delay for 1 second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records retrieved: 43007\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all data into a single DataFrame\n",
    "df0 = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "# Display the final record count\n",
    "print(f\"Total records retrieved: {len(df0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surveillance_network</th>\n",
       "      <th>season</th>\n",
       "      <th>mmwr_year</th>\n",
       "      <th>mmwr_week</th>\n",
       "      <th>age_group</th>\n",
       "      <th>sex</th>\n",
       "      <th>race_ethnicity</th>\n",
       "      <th>site</th>\n",
       "      <th>weekly_rate</th>\n",
       "      <th>cumulative_rate</th>\n",
       "      <th>_weekenddate</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FluSurv-NET</td>\n",
       "      <td>2018-19</td>\n",
       "      <td>2018</td>\n",
       "      <td>40</td>\n",
       "      <td>Overall</td>\n",
       "      <td>Overall</td>\n",
       "      <td>AI/AN, non-Hispanic</td>\n",
       "      <td>Overall</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-10-06T00:00:00.000</td>\n",
       "      <td>Unadjusted Rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FluSurv-NET</td>\n",
       "      <td>2018-19</td>\n",
       "      <td>2018</td>\n",
       "      <td>41</td>\n",
       "      <td>Overall</td>\n",
       "      <td>Overall</td>\n",
       "      <td>AI/AN, non-Hispanic</td>\n",
       "      <td>Overall</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-10-13T00:00:00.000</td>\n",
       "      <td>Unadjusted Rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FluSurv-NET</td>\n",
       "      <td>2018-19</td>\n",
       "      <td>2018</td>\n",
       "      <td>42</td>\n",
       "      <td>Overall</td>\n",
       "      <td>Overall</td>\n",
       "      <td>AI/AN, non-Hispanic</td>\n",
       "      <td>Overall</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-10-20T00:00:00.000</td>\n",
       "      <td>Unadjusted Rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FluSurv-NET</td>\n",
       "      <td>2018-19</td>\n",
       "      <td>2018</td>\n",
       "      <td>43</td>\n",
       "      <td>Overall</td>\n",
       "      <td>Overall</td>\n",
       "      <td>AI/AN, non-Hispanic</td>\n",
       "      <td>Overall</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-10-27T00:00:00.000</td>\n",
       "      <td>Unadjusted Rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FluSurv-NET</td>\n",
       "      <td>2018-19</td>\n",
       "      <td>2018</td>\n",
       "      <td>44</td>\n",
       "      <td>Overall</td>\n",
       "      <td>Overall</td>\n",
       "      <td>AI/AN, non-Hispanic</td>\n",
       "      <td>Overall</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-11-03T00:00:00.000</td>\n",
       "      <td>Unadjusted Rate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  surveillance_network   season  mmwr_year  mmwr_week age_group      sex  \\\n",
       "0          FluSurv-NET  2018-19       2018         40   Overall  Overall   \n",
       "1          FluSurv-NET  2018-19       2018         41   Overall  Overall   \n",
       "2          FluSurv-NET  2018-19       2018         42   Overall  Overall   \n",
       "3          FluSurv-NET  2018-19       2018         43   Overall  Overall   \n",
       "4          FluSurv-NET  2018-19       2018         44   Overall  Overall   \n",
       "\n",
       "        race_ethnicity     site  weekly_rate  cumulative_rate  \\\n",
       "0  AI/AN, non-Hispanic  Overall          0.0              0.0   \n",
       "1  AI/AN, non-Hispanic  Overall          0.0              0.0   \n",
       "2  AI/AN, non-Hispanic  Overall          0.0              0.0   \n",
       "3  AI/AN, non-Hispanic  Overall          0.0              0.0   \n",
       "4  AI/AN, non-Hispanic  Overall          0.0              0.0   \n",
       "\n",
       "              _weekenddate             type  \n",
       "0  2018-10-06T00:00:00.000  Unadjusted Rate  \n",
       "1  2018-10-13T00:00:00.000  Unadjusted Rate  \n",
       "2  2018-10-20T00:00:00.000  Unadjusted Rate  \n",
       "3  2018-10-27T00:00:00.000  Unadjusted Rate  \n",
       "4  2018-11-03T00:00:00.000  Unadjusted Rate  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 rows of the dataframe\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43007 entries, 0 to 43006\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   surveillance_network  43007 non-null  object \n",
      " 1   season                43007 non-null  object \n",
      " 2   mmwr_year             43007 non-null  int64  \n",
      " 3   mmwr_week             43007 non-null  int64  \n",
      " 4   age_group             43007 non-null  object \n",
      " 5   sex                   43007 non-null  object \n",
      " 6   race_ethnicity        43007 non-null  object \n",
      " 7   site                  43007 non-null  object \n",
      " 8   weekly_rate           42739 non-null  float64\n",
      " 9   cumulative_rate       42739 non-null  float64\n",
      " 10  _weekenddate          43007 non-null  object \n",
      " 11  type                  43007 non-null  object \n",
      "dtypes: float64(2), int64(2), object(8)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Verify the data types of the columns\n",
    "df0.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "surveillance_network      0\n",
       "season                    0\n",
       "mmwr_year                 0\n",
       "mmwr_week                 0\n",
       "age_group                 0\n",
       "sex                       0\n",
       "race_ethnicity            0\n",
       "site                      0\n",
       "weekly_rate             268\n",
       "cumulative_rate         268\n",
       "_weekenddate              0\n",
       "type                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in the dataframe\n",
    "df0.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "df0.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "surveillance_network    0\n",
       "season                  0\n",
       "mmwr_year               0\n",
       "mmwr_week               0\n",
       "age_group               0\n",
       "sex                     0\n",
       "race_ethnicity          0\n",
       "site                    0\n",
       "weekly_rate             0\n",
       "cumulative_rate         0\n",
       "_weekenddate            0\n",
       "type                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that there are no missing values\n",
    "df0.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the age_group rows to delete.\n",
    "\n",
    "# Create a list of age groups to drop (they overlap with other age groups)\n",
    "agegroups_to_drop = ['0-4 years', '18-49 years', '5-17 years', '65+ years', '75+years']\n",
    "\n",
    "# Create a mask to filter the rows\n",
    "mask = df0['age_group'].isin(agegroups_to_drop)\n",
    "\n",
    "# Drop the rows that are not in the list\n",
    "df0.drop(df0[mask].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows where weekly_rate and cumulative_rate are 0\n",
    "df0 = df0[df0['weekly_rate'] != 0]\n",
    "df0 = df0[df0['cumulative_rate'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 35015 entries, 6 to 43006\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   surveillance_network  35015 non-null  object \n",
      " 1   season                35015 non-null  object \n",
      " 2   mmwr_year             35015 non-null  int64  \n",
      " 3   mmwr_week             35015 non-null  int64  \n",
      " 4   age_group             35015 non-null  object \n",
      " 5   sex                   35015 non-null  object \n",
      " 6   race_ethnicity        35015 non-null  object \n",
      " 7   site                  35015 non-null  object \n",
      " 8   weekly_rate           35015 non-null  float64\n",
      " 9   cumulative_rate       35015 non-null  float64\n",
      " 10  _weekenddate          35015 non-null  object \n",
      " 11  type                  35015 non-null  object \n",
      "dtypes: float64(2), int64(2), object(8)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Verify the records have been dropped\n",
    "df0.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns that are not needed\n",
    "df0.drop(columns=['mmwr_year', 'mmwr_week'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Race/Ethnicity values\n",
    "df0['race_ethnicity'] = df0['race_ethnicity'].replace('AI/AN, non-Hispanic', 'American Indian/Alaska Native')\n",
    "df0['race_ethnicity'] = df0['race_ethnicity'].replace('A/PI, non-Hispanic', 'Asian/Pacific Islander')\n",
    "df0['race_ethnicity'] = df0['race_ethnicity'].replace('Black, non-Hispanic', 'Black/African American')\n",
    "df0['race_ethnicity'] = df0['race_ethnicity'].replace('White, non-Hispanic', 'White')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Age Group Values\n",
    "df0['age_group'] = df0['age_group'].replace('0-17 years (Children)', 'Children (0-17 years)')\n",
    "df0['age_group'] = df0['age_group'].replace('18+ years (Adults)', 'Adults (18+ years)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "df0.rename(columns={'surveillance_network': 'Network',\n",
    "                    'season': 'Season',\n",
    "                    'age_group': 'Age Group',\n",
    "                    'sex': 'Sex',\n",
    "                    'race_ethnicity': 'Race/Ethnicity',\n",
    "                    'site': 'State',\n",
    "                    'weekly_rate': 'Weekly Rate',\n",
    "                    'cumulative_rate': 'Cumulative Rate',\n",
    "                    '_weekenddate': 'Week Ending',\n",
    "                    'type': 'Type'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Week Ending' column to datetime format\n",
    "df0['Week Ending'] = pd.to_datetime(df0['Week Ending'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 35015 entries, 6 to 43006\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   Network          35015 non-null  object        \n",
      " 1   Season           35015 non-null  object        \n",
      " 2   Age Group        35015 non-null  object        \n",
      " 3   Sex              35015 non-null  object        \n",
      " 4   Race/Ethnicity   35015 non-null  object        \n",
      " 5   State            35015 non-null  object        \n",
      " 6   Weekly Rate      35015 non-null  float64       \n",
      " 7   Cumulative Rate  35015 non-null  float64       \n",
      " 8   Week Ending      35015 non-null  datetime64[ns]\n",
      " 9   Type             35015 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), object(7)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Verify the changes\n",
    "df0.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Network</th>\n",
       "      <th>Season</th>\n",
       "      <th>Age Group</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race/Ethnicity</th>\n",
       "      <th>State</th>\n",
       "      <th>Weekly Rate</th>\n",
       "      <th>Cumulative Rate</th>\n",
       "      <th>Week Ending</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FluSurv-NET</td>\n",
       "      <td>2018-19</td>\n",
       "      <td>Overall</td>\n",
       "      <td>Overall</td>\n",
       "      <td>American Indian/Alaska Native</td>\n",
       "      <td>Overall</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2018-11-17</td>\n",
       "      <td>Unadjusted Rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FluSurv-NET</td>\n",
       "      <td>2018-19</td>\n",
       "      <td>Overall</td>\n",
       "      <td>Overall</td>\n",
       "      <td>American Indian/Alaska Native</td>\n",
       "      <td>Overall</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2018-12-08</td>\n",
       "      <td>Unadjusted Rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FluSurv-NET</td>\n",
       "      <td>2018-19</td>\n",
       "      <td>Overall</td>\n",
       "      <td>Overall</td>\n",
       "      <td>American Indian/Alaska Native</td>\n",
       "      <td>Overall</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2018-12-15</td>\n",
       "      <td>Unadjusted Rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FluSurv-NET</td>\n",
       "      <td>2018-19</td>\n",
       "      <td>Overall</td>\n",
       "      <td>Overall</td>\n",
       "      <td>American Indian/Alaska Native</td>\n",
       "      <td>Overall</td>\n",
       "      <td>5.4</td>\n",
       "      <td>9.3</td>\n",
       "      <td>2018-12-22</td>\n",
       "      <td>Unadjusted Rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FluSurv-NET</td>\n",
       "      <td>2018-19</td>\n",
       "      <td>Overall</td>\n",
       "      <td>Overall</td>\n",
       "      <td>American Indian/Alaska Native</td>\n",
       "      <td>Overall</td>\n",
       "      <td>5.4</td>\n",
       "      <td>14.7</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>Unadjusted Rate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Network   Season Age Group      Sex                 Race/Ethnicity  \\\n",
       "6   FluSurv-NET  2018-19   Overall  Overall  American Indian/Alaska Native   \n",
       "9   FluSurv-NET  2018-19   Overall  Overall  American Indian/Alaska Native   \n",
       "10  FluSurv-NET  2018-19   Overall  Overall  American Indian/Alaska Native   \n",
       "11  FluSurv-NET  2018-19   Overall  Overall  American Indian/Alaska Native   \n",
       "12  FluSurv-NET  2018-19   Overall  Overall  American Indian/Alaska Native   \n",
       "\n",
       "      State  Weekly Rate  Cumulative Rate Week Ending             Type  \n",
       "6   Overall          0.5              0.5  2018-11-17  Unadjusted Rate  \n",
       "9   Overall          1.0              1.5  2018-12-08  Unadjusted Rate  \n",
       "10  Overall          2.5              3.9  2018-12-15  Unadjusted Rate  \n",
       "11  Overall          5.4              9.3  2018-12-22  Unadjusted Rate  \n",
       "12  Overall          5.4             14.7  2018-12-29  Unadjusted Rate  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 rows of the dataframe\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data to a CSV file\n",
    "df0.to_csv('cleaned_respnet_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
